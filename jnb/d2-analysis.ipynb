{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Day 2: Getting started with data analysis\"\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "{{< include _include_d2.qmd >}}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: true\n",
        "#| echo: false\n",
        "#| output: false\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "#df = pd.read_csv('/home/sol-nhl/rnd/d/cca-cce/csv/iris.tsv', sep='\\t')\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/nils-holmberg/cca-cce/main/csv/iris.csv', sep='\\t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import data files\n",
        "\n",
        "To read a CSV file into a Pandas DataFrame, you'll first need to install the Pandas library if you haven't already. You can install it using pip with the command `pip install pandas`. Once installed, you can use the `read_csv()` function to load the data from the file into a DataFrame. The function takes the file path as an argument and returns a DataFrame containing the data. Here's how you can read the uploaded file, \"iris.csv\", into a Pandas DataFrame:\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "df = pd.read_csv('/path/to/your/iris.csv')\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(df.head())\n",
        "```\n",
        "\n",
        "Replace `'/path/to/your/iris.csv'` with the actual path where your file is located. This will give you a DataFrame `df` that contains all the data from \"iris.csv\".\n",
        "\n",
        "## Selecting and filtering\n",
        "\n",
        "In Pandas, two basic yet powerful operations are selecting specific columns and filtering rows. To select columns, you can use the syntax `df[['column1', 'column2']]`, which creates a new DataFrame containing only the selected columns. For example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: true\n",
        "#| echo: true\n",
        "#| output: true\n",
        "\n",
        "# To select 'sepal_length' and 'species' columns\n",
        "selected_columns = df[['sepal_length', 'species']]\n",
        "# Show the first few rows of the resulting DataFrame\n",
        "selected_columns.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To filter rows based on a condition, boolean indexing can be employed. The syntax `df[df['column'] > value]` filters rows where the values in the specified column meet the condition. For instance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: true\n",
        "#| echo: true\n",
        "#| output: true\n",
        "\n",
        "# To filter rows where 'sepal_length' is greater than 5\n",
        "filtered_rows = df[df['sepal_length'] > 5]\n",
        "# Show the first few rows of the resulting DataFrame\n",
        "filtered_rows.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Both operations return new DataFrames, which can then be used for further analysis.\n",
        "\n",
        "## Grouping and summarizing\n",
        "\n",
        "Grouping and summarizing data in Pandas is primarily achieved using the `groupby()` function. This function allows you to group rows based on one or multiple columns, and then you can apply aggregation methods like `mean()`, `sum()`, or `count()` to summarize the data. For instance, if you want to find the average measurements for each species in the `df` DataFrame, you can group by the 'species' column and then apply the `mean()` function to get the average for each numerical column.\n",
        "\n",
        "Here's an inline code example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: true\n",
        "#| echo: true\n",
        "#| output: true\n",
        "\n",
        "# Group by 'species' and calculate the mean for each numerical column\n",
        "grouped_by_species_mean = df.groupby('species').mean()\n",
        "# Show the first few rows of the resulting DataFrame\n",
        "grouped_by_species_mean.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This will give you a new DataFrame that contains the summarized data, facilitating easier comparisons between different groups.\n",
        "\n",
        "Let's try another example. Reading the Iris Dataset and Analyzing Sepal Length with Pandas. The Iris dataset, a foundational dataset in data science, comprises measurements of sepals and petals for three iris species. Using the Pandas library in Python, one can effortlessly read and analyze this dataset. To read the dataset into a DataFrame, utilize `pd.read_csv()` if you have a CSV file. With the DataFrame loaded, one can employ the `groupby()` method to group by species, and then use the `mean()` and `std()` functions to compute the mean and standard deviation of the `sepal_length` for each species. Here's a code example that demonstrates the process:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: true\n",
        "#| echo: true\n",
        "#| output: true\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Sample data mimicking the Iris dataset structure\n",
        "data = {\n",
        "    'sepal_length': [5.1, 4.9, 5.8, 6.4, 5.7],\n",
        "    'sepal_width': [3.5, 3.0, 2.7, 3.2, 3.0],\n",
        "    'species': ['setosa', 'setosa', 'virginica', 'virginica', 'versicolor']\n",
        "}\n",
        "df_data = pd.DataFrame(data)\n",
        "\n",
        "# Group by species and calculate mean and standard deviation for sepal_length\n",
        "means = df_data.groupby('species')['sepal_length'].mean()\n",
        "std_devs = df_data.groupby('species')['sepal_length'].std()\n",
        "# Calculate both mean and std for sepal_length grouped by species in one line\n",
        "stats = df_data.groupby('species')['sepal_length'].agg(['mean', 'std'])\n",
        "\n",
        "print(\"Mean Sepal Length by Species:\")\n",
        "print(means)\n",
        "print(\"\\nStandard Deviation of Sepal Length by Species:\")\n",
        "print(std_devs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Executing the above code will yield the mean and standard deviation of `sepal_length` for each species in the sample data.\n",
        "\n",
        "## Statistical analysis\n",
        "\n",
        "Regression analysis is used to explore the relationship between dependent and independent variables. In Python, Scikit-learn is a popular library for performing regression. You typically use the `LinearRegression` class to create a regression model. After separating your features and target variables, you can fit the model using the `fit()` method and make predictions with `predict()`. For example, if you want to predict 'petal_length' based on 'sepal_length' in the `df` DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: true\n",
        "#| echo: true\n",
        "#| output: true\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import pandas as pd\n",
        "\n",
        "# Prepare the features and target variable\n",
        "X = df[['sepal_length']]  # Feature (independent variable)\n",
        "y = df['petal_length']  # Target (dependent variable)\n",
        "\n",
        "# Create a LinearRegression object\n",
        "model = LinearRegression()\n",
        "\n",
        "# Fit the model to the data\n",
        "model.fit(X, y)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X)\n",
        "\n",
        "# Create a DataFrame to display the analysis result\n",
        "result_df = pd.DataFrame({'Actual': y, 'Predicted': predictions})\n",
        "# Show the first few rows of the result DataFrame\n",
        "result_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This will create a DataFrame `result_df` that contains both the actual and predicted 'petal_length', facilitating the evaluation of the model's performance.\n",
        "\n",
        "## Write data files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: true\n",
        "#| echo: true\n",
        "#| output: true\n",
        "\n",
        "# write to text file\n",
        "df.to_csv(\"../../tmp/some.tsv\", sep='\\t', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Try it yourself!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: true\n",
        "#| echo: true\n",
        "#| output: true\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/nils-holmberg/cca-cce/main/csv/palmerpenguins.tsv', sep='\\t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![palmer penguins](https://nils-holmberg.github.io/cca-cce/res/img/lter_penguins.png){#fig-penguins height=214px width=360px}\n",
        "\n",
        "**Tasks:**\n",
        "\n",
        "1. Display the first 5 rows of the dataset to get a quick overview.\n",
        "2. Show the summary statistics (mean, standard deviation, min, max, etc.) for numerical columns.\n",
        "3. Determine the number of unique species in the dataset.\n",
        "4. Filter the dataset to show only Adelie penguins from Torgersen island.\n",
        "5. Calculate the average bill length of male penguins across all species.\n",
        "6. Find out the year with the highest recorded average body mass for penguins.\n",
        "7. Determine the number of missing values in each column.\n",
        "8. Display all records for penguins with a flipper length greater than 210 mm.\n",
        "9. Group the data by species and calculate the average bill depth for each group.\n",
        "10. Count the number of penguins on each island."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| output: false\n",
        "\n",
        "# Task 1\n",
        "overview = penguins_df.head()\n",
        "\n",
        "# Task 2\n",
        "summary_statistics = penguins_df.describe()\n",
        "\n",
        "# Task 3\n",
        "unique_species = penguins_df['species'].nunique()\n",
        "\n",
        "# Task 4\n",
        "adelie_torgersen = penguins_df[(penguins_df['species'] == 'Adelie') & (penguins_df['island'] == 'Torgersen')]\n",
        "\n",
        "# Task 5\n",
        "average_bill_length_male = penguins_df[penguins_df['sex'] == 'male']['bill_length_mm'].mean()\n",
        "\n",
        "# Task 6\n",
        "year_highest_body_mass = penguins_df.groupby('year')['body_mass_g'].mean().idxmax()\n",
        "\n",
        "# Task 7\n",
        "missing_values = penguins_df.isnull().sum()\n",
        "\n",
        "# Task 8\n",
        "large_flippers = penguins_df[penguins_df['flipper_length_mm'] > 210]\n",
        "\n",
        "# Task 9\n",
        "avg_bill_depth_by_species = penguins_df.groupby('species')['bill_depth_mm'].mean()\n",
        "\n",
        "# Task 10\n",
        "penguins_by_island = penguins_df['island'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These tasks and their solutions offer a comprehensive introduction to basic data analysis functionalities in Pandas.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}