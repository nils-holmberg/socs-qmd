{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nils-holmberg/socs-qmd/blob/main/jnb/lecture6_cv3.ipynb)"
      ],
      "metadata": {
        "id": "hSTShk6fTniQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# load dataset\n",
        "\n",
        "## recommended solution for gdown problem"
      ],
      "metadata": {
        "id": "ZwhVlVgsuvjE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# downgrade gdown to earlier version\n",
        "!pip install gdown==4.6"
      ],
      "metadata": {
        "id": "zsEHELW-vt3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1T9S32UwmDnUd6YbxRYfyG7-gud8jh2Y_\n"
      ],
      "metadata": {
        "id": "D8Ard14Zu0KI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# continue with analysis"
      ],
      "metadata": {
        "id": "K94vU1Dhyl9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "# Path to the video file\n",
        "video_path = 'content-video.mp4'\n",
        "\n",
        "# Create a VideoCapture object\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Check if video opened successfully\n",
        "if not cap.isOpened():\n",
        "    print(\"Error: Could not open video.\")\n",
        "    exit()\n",
        "\n",
        "# Directory to save frames\n",
        "save_dir = 'images-video'\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "frame_idx = 0\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    # Break the loop if there are no more frames\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Save every 100th frame\n",
        "    if frame_idx % 100 == 0:\n",
        "        # Filename with 5 leading zeroes\n",
        "        save_path = os.path.join(save_dir, f'frame_{frame_idx:05d}.jpg')\n",
        "        cv2.imwrite(save_path, frame)\n",
        "        print(f'Saved frame {frame_idx:05d}')\n",
        "\n",
        "    frame_idx += 1\n",
        "\n",
        "# Release the VideoCapture object\n",
        "cap.release()\n"
      ],
      "metadata": {
        "id": "oHzjKDdyylYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# emotion detection\n",
        "\n",
        "- for human face images"
      ],
      "metadata": {
        "id": "y-jSdK-KTQHI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install the deepface package\n",
        "# You can run this command in your terminal or command prompt\n",
        "!pip install deepface\n"
      ],
      "metadata": {
        "id": "jkpzsxoNcNWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from io import BytesIO\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# URL of an image commonly used for illustrating emotion detection\n",
        "image_url = 'your_image_url_here'  # Replace with your desired image URL\n",
        "\n",
        "# Download the image\n",
        "response = requests.get(image_url)\n",
        "img = cv2.imdecode(np.frombuffer(response.content, np.uint8), 1)\n"
      ],
      "metadata": {
        "id": "IeNPDT14Ue1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "# Load your image\n",
        "image_path = '/content/images-video/frame_02100.jpg'  # Replace with your image path\n",
        "image_path = \"/content/Screenshot_20230125-113433_Chrome.jpg\"\n",
        "img = cv2.imread(image_path)\n"
      ],
      "metadata": {
        "id": "R2cJr_ROd_C7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from deepface import DeepFace\n",
        "\n",
        "# Analyze the image for emotions\n",
        "try:\n",
        "    analysis = DeepFace.analyze(img, actions=['emotion'])\n",
        "\n",
        "    # First, print the entire analysis to understand its structure\n",
        "    print(\"Full Analysis:\", analysis)\n",
        "\n",
        "    # Then, access the emotion data (modify this according to the actual structure)\n",
        "    print(\"Emotions:\", analysis[\"emotion\"])\n",
        "except Exception as e:\n",
        "    print(\"Error:\", e)\n"
      ],
      "metadata": {
        "id": "jrGfYqAOe0W-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# more info\n",
        "\n",
        "- [package](https://pypi.org/project/deepface/)\n",
        "- [github](https://github.com/serengil/deepface)"
      ],
      "metadata": {
        "id": "dIOO0TxSWIAO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QoaDNqbGWUWk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}