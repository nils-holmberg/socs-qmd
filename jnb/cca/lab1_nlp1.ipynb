{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nils-holmberg/socs-qmd/blob/main/jnb/lab1_nlp1.ipynb)"
      ],
      "metadata": {
        "id": "HYTz_3JrYEXZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# download data file"
      ],
      "metadata": {
        "id": "24wcStHU0SiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "5R6GpEuz0mC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfzmzFSRUtiX"
      },
      "outputs": [],
      "source": [
        "#!pip install gdown\n",
        "!gdown https://drive.google.com/uc?id=1EMzJxxoBaN_NbvF7xhoc09K82vQ6H_LX"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fp = \"content.xlsx\"\n",
        "df = pd.read_excel(fp, header=None)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "zTYK8YAS0twv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fp = \"https://raw.githubusercontent.com/nils-holmberg/socs-qmd/main/csv/content.tsv\"\n",
        "df = pd.read_csv(fp, header=None, sep=\"\\t\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "vLa3fWin1K7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = ['id', 'image', 'text']\n",
        "df.head()"
      ],
      "metadata": {
        "id": "g-YKbCHz8RmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# analyze text data"
      ],
      "metadata": {
        "id": "G_SN9bmE26JV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load spaCy's English language model\n",
        "# You might need to run !python -m spacy download en_core_web_sm to download the model\n",
        "!python -m spacy download en_core_web_sm\n",
        "nlp = spacy.load('en_core_web_sm')\n"
      ],
      "metadata": {
        "id": "sV9MRwOo29Vt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def spacy_clean_text(doc):\n",
        "    # Tokenize, lemmatize, remove stop words and non-alphabetic tokens\n",
        "    tokens = [token.lemma_.lower() for token in doc if not token.is_stop and token.is_alpha]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Load your data\n",
        "data = df\n",
        "\n",
        "# Apply spaCy preprocessing to the text column\n",
        "data['spacy_cleaned_text'] = data['text'].apply(lambda x: spacy_clean_text(nlp(x)))\n",
        "\n",
        "data.head()"
      ],
      "metadata": {
        "id": "5KGPna0E3GeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a frequency table\n",
        "word_freq = data['spacy_cleaned_text'].str.split(expand=True).stack().value_counts()\n",
        "\n",
        "# Display the frequency table\n",
        "word_freq"
      ],
      "metadata": {
        "id": "Z9-sy6_X9jyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the Series to a DataFrame\n",
        "\n",
        "word_freq_df = word_freq.to_frame().reset_index()\n",
        "word_freq_df.columns = ['term','freq']\n",
        "word_freq_df.head()"
      ],
      "metadata": {
        "id": "bJ78voJ7_r3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting the top N words\n",
        "top_n = 10  # You can change this number to display more or fewer words\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.barplot(x='freq', y='term', data=word_freq_df.head(top_n), palette='viridis')\n",
        "\n",
        "plt.title(f'Top {top_n} Most Frequent Words')\n",
        "plt.xlabel('freq')\n",
        "plt.ylabel('term')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OZcn2k9bCJaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to process the text and return a spaCy Doc object\n",
        "def process_text(text):\n",
        "    doc = nlp(text)\n",
        "    return [\n",
        "        {\n",
        "            'token': token.text,\n",
        "            'lemma': token.lemma_,\n",
        "            'part_of_speech': token.pos_,\n",
        "            'entity': token.ent_type_ if token.ent_type_ else 'None'\n",
        "        }\n",
        "        for token in doc\n",
        "    ]\n",
        "\n",
        "# Apply the function to the 'text' column and store the results in a new column 'spacy_nlp'\n",
        "data['spacy_nlp'] = data['text'].apply(process_text)\n",
        "\n",
        "# Display the DataFrame with the new column\n",
        "data.spacy_nlp.head()"
      ],
      "metadata": {
        "id": "wvwDTx_PE6WB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the spacy_nlp column and join with the id column\n",
        "spacy_df = data.explode('spacy_nlp')\n",
        "nlp_df = pd.concat([spacy_df[['id']], spacy_df['spacy_nlp'].apply(pd.Series)], axis=1)\n",
        "\n",
        "# Display the new DataFrame\n",
        "nlp_df"
      ],
      "metadata": {
        "id": "wUCcMN3GJ6hV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify your desired output file path\n",
        "fp = 'nlp.tsv'\n",
        "\n",
        "# Save the DataFrame as a TSV file\n",
        "nlp_df.to_csv(fp, sep='\\t', index=False)"
      ],
      "metadata": {
        "id": "GygTWJL6MDQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# vectorize text data"
      ],
      "metadata": {
        "id": "8vV6uYMZXfd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Creating a Bag of Words model\n",
        "vectorizer = CountVectorizer()\n",
        "bow_model = vectorizer.fit_transform(data['spacy_cleaned_text'])\n",
        "\n"
      ],
      "metadata": {
        "id": "P1_D9qcD9yiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting BoW model to a DataFrame for better visibility\n",
        "bow_df = pd.DataFrame(bow_model.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "# Display the first few rows of the BoW DataFrame\n",
        "print(bow_df.head())"
      ],
      "metadata": {
        "id": "Y1bloJLj_Ird"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "vectorizer.vocabulary_"
      ],
      "metadata": {
        "id": "hI9Bti_pRHVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "print(vectorizer.transform(data['spacy_cleaned_text']))"
      ],
      "metadata": {
        "id": "PkkCTlnSReWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "vectorizer.transform(data['spacy_cleaned_text']).toarray()"
      ],
      "metadata": {
        "id": "kLzYnfjNSKVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def read_text_files(directory):\n",
        "    # Initialize an empty list to store the file names and text content\n",
        "    data = []\n",
        "\n",
        "    # Iterate over all files in the directory\n",
        "    for filename in os.listdir(directory):\n",
        "        # Check if the file is a text file\n",
        "        if filename.endswith('.txt'):\n",
        "            # Construct the full file path\n",
        "            file_path = os.path.join(directory, filename)\n",
        "\n",
        "            # Read the content of the file\n",
        "            with open(file_path, 'r', encoding='utf-8') as file:\n",
        "                content = file.read()\n",
        "                data.append([filename, content])\n",
        "\n",
        "    # Create a DataFrame with file names and text content\n",
        "    df = pd.DataFrame(data, columns=['File Name', 'Content'])\n",
        "\n",
        "    return df\n",
        "\n",
        "# Specify the directory containing the text files\n",
        "directory_path = 'data-text'  # Replace with your directory path\n",
        "\n",
        "# Call the function and get the DataFrame\n",
        "text_df = read_text_files(directory_path)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(text_df)\n"
      ],
      "metadata": {
        "id": "SPYvRx7mS7dv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}