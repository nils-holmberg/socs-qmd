{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "OKRDj4zw5fW4"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nils-holmberg/socs-qmd/blob/main/jnb/lab5_cv2.ipynb)"
      ],
      "metadata": {
        "id": "cgjbhLsQ04g9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "6S071Ga38hiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# image dataset"
      ],
      "metadata": {
        "id": "VBlkruw903w6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgpiOcF78gTN"
      },
      "outputs": [],
      "source": [
        "!gdown https://drive.google.com/uc?id=1sBsckDIyQJ-zTsEpjCntYMIJcbBpF3wk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip content-images.zip"
      ],
      "metadata": {
        "id": "waLkp4aL8x-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# For demonstration, creating a sample grayscale image\n",
        "#image = np.random.randint(0, 256, (200, 200), dtype=np.uint8)\n",
        "# Read the image using OpenCV\n",
        "image_path = 'images/ibs-92.jpg'  # Replace with your image path\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# Initialize ORB detector\n",
        "orb = cv2.ORB_create()\n",
        "\n",
        "# Detect ORB keypoints and descriptors in the grayscale version of the image\n",
        "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "keypoints, descriptors = orb.detectAndCompute(gray_image, None)\n",
        "\n",
        "# Draw keypoints on the original color image\n",
        "orb_image = cv2.drawKeypoints(image, keypoints, None, color=(0, 255, 0), flags=0)\n",
        "\n",
        "# Display the color image with ORB features\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(cv2.cvtColor(orb_image, cv2.COLOR_BGR2RGB))\n",
        "plt.title('ORB Features on Color Image')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xD4u1Yqd9oGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# color clustering"
      ],
      "metadata": {
        "id": "LzH21AWa2bSx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from collections import Counter\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2"
      ],
      "metadata": {
        "id": "F9pTP3LY2a3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility function, rgb to hex\n",
        "def rgb2hex(rgb):\n",
        "    hex = \"#{:02x}{:02x}{:02x}\".format(int(rgb[0]), int(rgb[1]), int(rgb[2]))\n",
        "    return hex\n",
        "print(rgb2hex([255, 0, 0]))"
      ],
      "metadata": {
        "id": "IwiPXVDq3ujC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_color_cluster(path, k=6):\n",
        "    # load image\n",
        "    img_bgr = cv2.imread(path)\n",
        "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # resize image to speed up processing time\n",
        "    resized_img_rgb = cv2.resize(img_rgb, (64, 64), interpolation=cv2.INTER_AREA)\n",
        "    resized_img_rgb = img_rgb\n",
        "\n",
        "    # reshape the image to be a list of pixels\n",
        "    img_list = resized_img_rgb.reshape((resized_img_rgb.shape[0] * resized_img_rgb.shape[1], 3))\n",
        "\n",
        "    # cluster the pixels and assign labels\n",
        "    clt = KMeans(n_clusters=k)\n",
        "    labels = clt.fit_predict(img_list)\n",
        "\n",
        "    # count labels to find most popular\n",
        "    label_counts = Counter(labels)\n",
        "    total_count = sum(label_counts.values())\n",
        "\n",
        "    # subset out most popular centroid\n",
        "    center_colors = list(clt.cluster_centers_)\n",
        "    ordered_colors = [center_colors[i]/255 for i in label_counts.keys()]\n",
        "    color_labels = [rgb2hex(ordered_colors[i]*255) for i in label_counts.keys()]\n",
        "\n",
        "    #print(label_counts.values())\n",
        "    #print(color_labels)\n",
        "\n",
        "    # plots\n",
        "    plt.figure(figsize=(14, 8))\n",
        "    #plt.subplot(221)\n",
        "    #plt.imshow(img_rgb)\n",
        "    #plt.axis('off')\n",
        "\n",
        "    #plt.subplot(222)\n",
        "    plt.pie(label_counts.values(), labels=color_labels, colors=ordered_colors, startangle=90)\n",
        "    plt.axis('equal')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "cGXT4vx137MC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = 'images/ibs-92.jpg'  # Replace with your image path\n",
        "image_color_cluster(image_path, k=10)"
      ],
      "metadata": {
        "id": "bhW6jpLM4Nn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# video dataset"
      ],
      "metadata": {
        "id": "UwbWedZR1lE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1T9S32UwmDnUd6YbxRYfyG7-gud8jh2Y_\n"
      ],
      "metadata": {
        "id": "FFnmjMCX-2wL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "# Path to the video file\n",
        "video_path = 'content-video.mp4'\n",
        "\n",
        "# Create a VideoCapture object\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Check if video opened successfully\n",
        "if not cap.isOpened():\n",
        "    print(\"Error: Could not open video.\")\n",
        "    exit()\n",
        "\n",
        "# Directory to save frames\n",
        "save_dir = 'images-video'\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "frame_idx = 0\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    # Break the loop if there are no more frames\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Save every 100th frame\n",
        "    if frame_idx % 100 == 0:\n",
        "        # Filename with 5 leading zeroes\n",
        "        save_path = os.path.join(save_dir, f'frame_{frame_idx:05d}.jpg')\n",
        "        cv2.imwrite(save_path, frame)\n",
        "        print(f'Saved frame {frame_idx:05d}')\n",
        "\n",
        "    frame_idx += 1\n",
        "\n",
        "# Release the VideoCapture object\n",
        "cap.release()\n"
      ],
      "metadata": {
        "id": "x5k3-XKp-6fu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# image ocr"
      ],
      "metadata": {
        "id": "OKRDj4zw5fW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q easyocr\n"
      ],
      "metadata": {
        "id": "k1QYaSVP8o4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import easyocr"
      ],
      "metadata": {
        "id": "135SsUj35eL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reader = easyocr.Reader(['ch_tra', 'en', 'sv'])\n",
        "reader = easyocr.Reader(['en'])"
      ],
      "metadata": {
        "id": "nJm1sLwn5o01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = reader.readtext('images-video/frame_00400.jpg')\n",
        "result"
      ],
      "metadata": {
        "id": "tQCi0rKz5scR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reader.readtext('images-video/frame_00400.jpg', detail=0)"
      ],
      "metadata": {
        "id": "6HIh-Oyk5vhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# image normalization"
      ],
      "metadata": {
        "id": "R85rRHYK5iI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "def resize_and_crop(img, size):\n",
        "    # Resize image to maintain aspect ratio\n",
        "    h, w, _ = img.shape\n",
        "    if h > w:\n",
        "        new_h, new_w = size * h / w, size\n",
        "    else:\n",
        "        new_h, new_w = size, size * w / h\n",
        "\n",
        "    new_h, new_w = int(new_h), int(new_w)\n",
        "    resized_img = cv2.resize(img, (new_w, new_h))\n",
        "\n",
        "    # Crop the center of the image\n",
        "    startx = new_w//2 - size//2\n",
        "    starty = new_h//2 - size//2\n",
        "    return resized_img[starty:starty+size, startx:startx+size]\n",
        "\n",
        "def normalize_image(img):\n",
        "    # Normalize pixel values to [0, 1]\n",
        "    return img / 255.0\n",
        "\n",
        "directory = 'images-video'\n",
        "output_directory = 'images-normalize'\n",
        "\n",
        "if not os.path.exists(output_directory):\n",
        "    os.makedirs(output_directory)\n",
        "\n",
        "for filename in os.listdir(directory):\n",
        "    if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
        "#    if filename.endswith('.jpg'):\n",
        "        img = cv2.imread(os.path.join(directory, filename))\n",
        "        img = resize_and_crop(img, 256)\n",
        "        normalized_img = normalize_image(img)\n",
        "\n",
        "        # Convert the normalized image back to 8-bit format\n",
        "        img_to_save = (normalized_img * 255).astype(np.uint8)\n",
        "\n",
        "        # Save the normalized image\n",
        "        output_path = os.path.join(output_directory, filename)\n",
        "        cv2.imwrite(output_path, img_to_save)\n"
      ],
      "metadata": {
        "id": "hjI2Iu-Z-_py"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# color histograms"
      ],
      "metadata": {
        "id": "TE5TRoa9koCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Read the image\n",
        "image = cv2.imread('images/ibs-92.jpg')\n",
        "\n",
        "# Calculate color histograms for each channel\n",
        "hist_r = cv2.calcHist([image], [0], None, [256], [0, 256])\n",
        "hist_g = cv2.calcHist([image], [1], None, [256], [0, 256])\n",
        "hist_b = cv2.calcHist([image], [2], None, [256], [0, 256])\n",
        "\n",
        "# Normalize histograms\n",
        "hist_r /= hist_r.sum()\n",
        "hist_g /= hist_g.sum()\n",
        "hist_b /= hist_b.sum()\n",
        "\n",
        "# Create subplots for the original image and histograms\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# Plot the original image\n",
        "axes[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "axes[0].set_title('Original Image')\n",
        "axes[0].axis('off')\n",
        "\n",
        "# Plot the color histograms using Seaborn\n",
        "sns.lineplot(x=np.arange(256), y=hist_r.squeeze(), color='red', ax=axes[1], label='Red')\n",
        "sns.lineplot(x=np.arange(256), y=hist_g.squeeze(), color='green', ax=axes[1], label='Green')\n",
        "sns.lineplot(x=np.arange(256), y=hist_b.squeeze(), color='blue', ax=axes[1], label='Blue')\n",
        "axes[1].set_title('Color Histograms')\n",
        "axes[1].set_xlabel('Pixel Value')\n",
        "axes[1].set_ylabel('Frequency')\n",
        "axes[1].legend()\n",
        "\n",
        "# Show the plots\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Pe0XiEW3krSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def compute_histogram(image, bins=256):\n",
        "    \"\"\"Compute the color histogram for an image.\"\"\"\n",
        "    histogram = [cv2.calcHist([image], [i], None, [bins], [0, 256]) for i in range(3)]\n",
        "    return np.concatenate(histogram).flatten()\n",
        "\n",
        "def calculate_similarity(hist_list):\n",
        "    \"\"\"Calculate histogram similarity matrix.\"\"\"\n",
        "    num_images = len(hist_list)\n",
        "    similarity_matrix = np.zeros((num_images, num_images))\n",
        "\n",
        "    for i in range(num_images):\n",
        "        for j in range(num_images):\n",
        "            similarity = cv2.compareHist(hist_list[i], hist_list[j], cv2.HISTCMP_CORREL)\n",
        "            similarity_matrix[i, j] = similarity\n",
        "\n",
        "    return similarity_matrix\n",
        "\n",
        "# Directory containing images\n",
        "image_directory = 'images'  # Replace with your directory path\n",
        "image_directory = 'images-normalize'  # Replace with your directory path\n",
        "\n",
        "# Load and process images\n",
        "image_files = [f for f in os.listdir(image_directory) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "histograms = []\n",
        "\n",
        "for file in image_files:\n",
        "    image_path = os.path.join(image_directory, file)\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is not None:\n",
        "        hist = compute_histogram(image)\n",
        "        histograms.append(hist)\n",
        "\n",
        "# Calculate the similarity matrix\n",
        "similarity_matrix = calculate_similarity(histograms)\n",
        "similarity_matrix = np.around(similarity_matrix, decimals=1)\n",
        "\n",
        "# Plotting the similarity matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "#sns.heatmap(similarity_matrix, annot=True, cmap='coolwarm')\n",
        "sns.heatmap(similarity_matrix, annot=False, cmap='coolwarm')\n",
        "plt.title('Image Histogram Similarity Matrix')\n",
        "plt.xlabel('Image Index')\n",
        "plt.ylabel('Image Index')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "iaDJGyNa9ANi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!rm images-normalize/ibs-*"
      ],
      "metadata": {
        "id": "btnVmGr5YV5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "\n",
        "# Function to compute the color histogram and similarity matrix\n",
        "# ... (same functions `compute_histogram` and `calculate_similarity` as before)\n",
        "\n",
        "# Directory containing images\n",
        "image_directory = 'images'  # Replace with your directory path\n",
        "image_directory = 'images-normalize'  # Replace with your directory path\n",
        "\n",
        "# Load and process images\n",
        "image_files = [f for f in os.listdir(image_directory) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "histograms = []\n",
        "\n",
        "for file in image_files:\n",
        "    image_path = os.path.join(image_directory, file)\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is not None:\n",
        "        hist = compute_histogram(image)\n",
        "        histograms.append(hist)\n",
        "\n",
        "# Calculate the similarity matrix\n",
        "similarity_matrix = calculate_similarity(histograms)\n",
        "\n",
        "# Perform hierarchical clustering\n",
        "Z = linkage(1 - similarity_matrix, method='average')\n",
        "\n",
        "# Plot dendrogram\n",
        "plt.figure(figsize=(12, 8))\n",
        "dendrogram(Z, labels=image_files, orientation='right')\n",
        "plt.title('Hierarchical Clustering Dendrogram')\n",
        "plt.xlabel('Distance')\n",
        "plt.ylabel('Image')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9MWlmZxJFsX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# clustering, explorative"
      ],
      "metadata": {
        "id": "7k-45mofW1-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1U3yly6qUlBBcWYfkMlRpZ47I6DjcRUna"
      ],
      "metadata": {
        "id": "EFyoFfWxW0Gf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip mnist-42k.zip"
      ],
      "metadata": {
        "id": "gIPYcsXyWz7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q supervision umap-learn"
      ],
      "metadata": {
        "id": "D1yUn3RqYrRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "\n",
        "def image_to_data_uri(image_path):\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        encoded_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
        "    return \"data:image/jpeg;base64,\" + encoded_image"
      ],
      "metadata": {
        "id": "KkGo2ZbCYEff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import supervision as sv\n",
        "import numpy as np\n",
        "\n",
        "#SOURCE_DIR = os.path.join(dataset.location, \"train\")\n",
        "SOURCE_DIR = os.path.join(\"MNIST-42000-images-1\", \"train\")\n",
        "PER_CLASS_IMAGE_COUNT = 500\n",
        "\n",
        "labels = []\n",
        "train = []\n",
        "images = []\n",
        "image_paths = []\n",
        "\n",
        "class_ids = sorted(os.listdir(SOURCE_DIR))\n",
        "\n",
        "for class_id in class_ids:\n",
        "    source_subdir = os.path.join(SOURCE_DIR, class_id)\n",
        "    for image_path in sv.list_files_with_extensions(source_subdir)[:PER_CLASS_IMAGE_COUNT]:\n",
        "        image = cv2.imread(str(image_path), cv2.IMREAD_GRAYSCALE)\n",
        "        labels.append(class_id)\n",
        "        images.append(image)\n",
        "        image_paths.append(str(image_path))\n",
        "        train.append(image.flatten())\n",
        "\n",
        "# class associated with image\n",
        "labels = np.array(labels)\n",
        "# features extracted from image\n",
        "train = np.array(train)\n",
        "# local image path\n",
        "image_paths = np.array(image_paths)\n",
        "# cached images\n",
        "image_data_uris = {path: image_to_data_uri(path) for path in image_paths}"
      ],
      "metadata": {
        "id": "tdKjP8CsYPqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "images_sample = random.sample(images, 9)\n",
        "sv.plot_images_grid(images_sample, grid_size=(3, 3))"
      ],
      "metadata": {
        "id": "SnvxeO6QZNLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import time\n",
        "\n",
        "start = time.time()\n",
        "tsne = TSNE(n_components = 3, random_state=0)\n",
        "projections = tsne.fit_transform(train)\n",
        "end = time.time()\n",
        "print(f\"generating projections with T-SNE took: {(end-start):.2f} sec\")"
      ],
      "metadata": {
        "id": "0D5lmDK0WzyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import numpy as np\n",
        "\n",
        "from typing import Dict\n",
        "from pathlib import Path\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "\n",
        "def display_projections(\n",
        "    labels: np.ndarray,\n",
        "    projections: np.ndarray,\n",
        "    image_paths: np.ndarray,\n",
        "    image_data_uris: Dict[str, str],\n",
        "    show_legend: bool = False,\n",
        "    show_markers_with_text: bool = True\n",
        ") -> None:\n",
        "    # Create a separate trace for each unique label\n",
        "    unique_labels = np.unique(labels)\n",
        "    traces = []\n",
        "    for unique_label in unique_labels:\n",
        "        mask = labels == unique_label\n",
        "        customdata_masked = image_paths[mask]\n",
        "        trace = go.Scatter3d(\n",
        "            x=projections[mask][:, 0],\n",
        "            y=projections[mask][:, 1],\n",
        "            z=projections[mask][:, 2],\n",
        "            mode='markers+text' if show_markers_with_text else 'markers',\n",
        "            text=labels[mask],\n",
        "            customdata=customdata_masked,\n",
        "            name=str(unique_label),\n",
        "            marker=dict(size=8),\n",
        "            hovertemplate=\"<b>class: %{text}</b><br>path: %{customdata}<extra></extra>\"\n",
        "        )\n",
        "        traces.append(trace)\n",
        "\n",
        "    # Create the 3D scatter plot\n",
        "    fig = go.Figure(data=traces)\n",
        "    fig.update_layout(\n",
        "        scene=dict(xaxis_title='X', yaxis_title='Y', zaxis_title='Z'),\n",
        "        width=1000,\n",
        "        height=1000,\n",
        "        showlegend=show_legend\n",
        "    )\n",
        "\n",
        "    # Convert the chart to an HTML div string and add an ID to the div\n",
        "    plotly_div = fig.to_html(full_html=False, include_plotlyjs=False, div_id=\"scatter-plot-3d\")\n",
        "\n",
        "    # Define your JavaScript code for copying text on point click\n",
        "    javascript_code = f\"\"\"\n",
        "    <script>\n",
        "        function displayImage(imagePath) {{\n",
        "            var imageElement = document.getElementById('image-display');\n",
        "            var placeholderText = document.getElementById('placeholder-text');\n",
        "            var imageDataURIs = {image_data_uris};\n",
        "            imageElement.src = imageDataURIs[imagePath];\n",
        "            imageElement.style.display = 'block';\n",
        "            placeholderText.style.display = 'none';\n",
        "        }}\n",
        "\n",
        "        // Get the Plotly chart element by its ID\n",
        "        var chartElement = document.getElementById('scatter-plot-3d');\n",
        "\n",
        "        // Add a click event listener to the chart element\n",
        "        chartElement.on('plotly_click', function(data) {{\n",
        "            var customdata = data.points[0].customdata;\n",
        "            displayImage(customdata);\n",
        "        }});\n",
        "    </script>\n",
        "    \"\"\"\n",
        "\n",
        "    # Create an HTML template including the chart div and JavaScript code\n",
        "    html_template = f\"\"\"\n",
        "    <!DOCTYPE html>\n",
        "    <html>\n",
        "        <head>\n",
        "            <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>\n",
        "            <style>\n",
        "                #image-container {{\n",
        "                    position: fixed;\n",
        "                    top: 0;\n",
        "                    left: 0;\n",
        "                    width: 200px;\n",
        "                    height: 200px;\n",
        "                    padding: 5px;\n",
        "                    border: 1px solid #ccc;\n",
        "                    background-color: white;\n",
        "                    z-index: 1000;\n",
        "                    box-sizing: border-box;\n",
        "                    display: flex;\n",
        "                    align-items: center;\n",
        "                    justify-content: center;\n",
        "                    text-align: center;\n",
        "                }}\n",
        "                #image-display {{\n",
        "                    width: 100%;\n",
        "                    height: 100%;\n",
        "                    object-fit: contain;\n",
        "                }}\n",
        "            </style>\n",
        "        </head>\n",
        "        <body>\n",
        "            {plotly_div}\n",
        "            <div id=\"image-container\">\n",
        "                <img id=\"image-display\" src=\"\" alt=\"Selected image\" style=\"display: none;\" />\n",
        "                <p id=\"placeholder-text\">Click on a data entry to display an image</p>\n",
        "            </div>\n",
        "            {javascript_code}\n",
        "        </body>\n",
        "    </html>\n",
        "    \"\"\"\n",
        "\n",
        "    # Display the HTML template in the Jupyter Notebook\n",
        "    display(HTML(html_template))"
      ],
      "metadata": {
        "id": "6HgRLlxnWzmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_projections(\n",
        "    labels=labels,\n",
        "    projections=projections,\n",
        "    image_paths=image_paths,\n",
        "    image_data_uris=image_data_uris\n",
        ")"
      ],
      "metadata": {
        "id": "i_M4JUJ6aNCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import umap\n",
        "import time\n",
        "\n",
        "start = time.time()\n",
        "projections = umap.UMAP(n_components=3).fit_transform(train)\n",
        "end = time.time()\n",
        "print(f\"generating projections with UMAP took: {(end-start):.2f} sec\")"
      ],
      "metadata": {
        "id": "0jVPseQqaoG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_projections(\n",
        "    labels=labels,\n",
        "    projections=projections,\n",
        "    image_paths=image_paths,\n",
        "    image_data_uris=image_data_uris\n",
        ")"
      ],
      "metadata": {
        "id": "1rKDrqWxbJra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# image embeddings"
      ],
      "metadata": {
        "id": "jN4SDAdmdz0E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import CLIPModel, CLIPProcessor\n",
        "from PIL import Image\n",
        "\n",
        "# Step 1: Install the transformers library (if not already installed)\n",
        "# pip install transformers\n",
        "\n",
        "# Step 2: Load the CLIP model and processor\n",
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "\n",
        "# Step 3: Load and process your image\n",
        "image = Image.open(\"images-normalize/frame_00000.jpg\")  # Replace with your image path\n",
        "inputs = processor(images=image, return_tensors=\"pt\")\n",
        "\n",
        "# Step 4: Generate image embeddings\n",
        "embeddings = model.get_image_features(**inputs)\n",
        "\n",
        "# The 'embeddings' variable now contains the image embeddings\n",
        "type(embeddings)"
      ],
      "metadata": {
        "id": "9dOLpOR1dzmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Convert the tensor to a NumPy array\n",
        "# If the tensor is on GPU, move it to CPU first\n",
        "embeddings_np = embeddings.cpu().detach().numpy()\n",
        "\n",
        "# Step 2: Create a Pandas DataFrame\n",
        "df = pd.DataFrame(embeddings_np)\n",
        "\n",
        "# Now 'df' is a Pandas DataFrame containing your embeddings\n",
        "df.head()"
      ],
      "metadata": {
        "id": "-ucd8UDVi1qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "\n",
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "\n",
        "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
        "image = Image.open(requests.get(url, stream=True).raw)\n",
        "\n",
        "inputs = processor(text=[\"a photo of a cat\", \"a photo of a dog\"], images=image, return_tensors=\"pt\", padding=True)\n",
        "\n",
        "outputs = model(**inputs)\n",
        "logits_per_image = outputs.logits_per_image # this is the image-text similarity score\n",
        "probs = logits_per_image.softmax(dim=1) # we can take the softmax to get the label probabilities\n",
        "\n",
        "print(probs)"
      ],
      "metadata": {
        "id": "jFSCG_DOobCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# image object detection"
      ],
      "metadata": {
        "id": "HPGeKJyR7MRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers\n",
        "!pip install -q timm\n"
      ],
      "metadata": {
        "id": "VN6t5-Nl7SY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "model = pipeline(\"object-detection\")"
      ],
      "metadata": {
        "id": "HT-Lm8eI7Qwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "rows_list = []\n",
        "for img in sorted(glob.glob('images-video/frame_*.jpg')):\n",
        "  dict1 = {}\n",
        "  res = model(img)\n",
        "  dict1.update({\"image\": img, \"result\": res})\n",
        "  rows_list.append(dict1)\n",
        "\n",
        "df = pd.DataFrame(rows_list)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "IYTtPDg17kJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rows_list = []\n",
        "for index, row in df.iterrows():\n",
        "  for i in row.result:\n",
        "    dict1 = {}\n",
        "    dict1.update({\"image\":row.image})\n",
        "    dict1.update(i)\n",
        "    rows_list.append(dict1)\n",
        "\n",
        "df_res = pd.DataFrame(rows_list)\n",
        "df_res.head()"
      ],
      "metadata": {
        "id": "mJbf6_6Y9cCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_res.label.value_counts().plot(kind='bar')"
      ],
      "metadata": {
        "id": "MiaHR_1P9kjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_res[df_res.image==\"images-video/frame_00100.jpg\"]"
      ],
      "metadata": {
        "id": "SbVliiwf9osW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "img = cv2.imread('images-video/frame_00100.jpg')\n",
        "for index,row in df_res[df_res.image==\"images-video/frame_00100.jpg\"].iterrows():\n",
        "  x1,y1,x2,y2 = list(row.box.values())\n",
        "  cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow(img)\n",
        "#cv2.imshow(\"display\", img)\n",
        "#cv2.imwrite(\"objects.png\", img)"
      ],
      "metadata": {
        "id": "xqUe8ol493s9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# image content inference"
      ],
      "metadata": {
        "id": "YO6lKKWSPsc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q mediapipe"
      ],
      "metadata": {
        "id": "1MUyIjCoG6hm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initialize MediaPipe Pose\n",
        "mp_pose = mp.solutions.pose\n",
        "pose = mp_pose.Pose(static_image_mode=True, model_complexity=1, enable_segmentation=True)\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "\n",
        "# Read an image\n",
        "image_path = 'images-video/frame_02800.jpg'  # Replace with the path to your image\n",
        "image_path = 'images-video/frame_00400.jpg'  # Replace with the path to your image\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# Check if image is loaded\n",
        "if image is None:\n",
        "    print(\"Error: Image not found.\")\n",
        "else:\n",
        "    # Convert the BGR image to RGB\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Process the image and find the pose\n",
        "    results = pose.process(image_rgb)\n",
        "\n",
        "    # Draw pose landmarks on the image\n",
        "    if results.pose_landmarks:\n",
        "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
        "\n",
        "    # Convert back to BGR for displaying with OpenCV\n",
        "    image_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    # Display the image\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Release resources\n",
        "pose.close()\n"
      ],
      "metadata": {
        "id": "l93XkAq4PzNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YZt6W4H6QvI8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}