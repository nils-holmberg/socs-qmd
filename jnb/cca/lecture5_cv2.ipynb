{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nils-holmberg/socs-qmd/blob/main/jnb/lecture5_cv2.ipynb)"
      ],
      "metadata": {
        "id": "cgjbhLsQ04g9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "6S071Ga38hiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# image dataset"
      ],
      "metadata": {
        "id": "VBlkruw903w6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgpiOcF78gTN"
      },
      "outputs": [],
      "source": [
        "!gdown https://drive.google.com/uc?id=1sBsckDIyQJ-zTsEpjCntYMIJcbBpF3wk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip content-images.zip"
      ],
      "metadata": {
        "id": "waLkp4aL8x-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# For demonstration, creating a sample grayscale image\n",
        "#image = np.random.randint(0, 256, (200, 200), dtype=np.uint8)\n",
        "# Read the image using OpenCV\n",
        "image_path = 'images/ibs-92.jpg'  # Replace with your image path\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# Initialize ORB detector\n",
        "orb = cv2.ORB_create()\n",
        "\n",
        "# Detect ORB keypoints and descriptors in the grayscale version of the image\n",
        "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "keypoints, descriptors = orb.detectAndCompute(gray_image, None)\n",
        "\n",
        "# Draw keypoints on the original color image\n",
        "orb_image = cv2.drawKeypoints(image, keypoints, None, color=(0, 255, 0), flags=0)\n",
        "\n",
        "# Display the color image with ORB features\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(cv2.cvtColor(orb_image, cv2.COLOR_BGR2RGB))\n",
        "plt.title('ORB Features on Color Image')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xD4u1Yqd9oGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# color clustering"
      ],
      "metadata": {
        "id": "LzH21AWa2bSx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from collections import Counter\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2"
      ],
      "metadata": {
        "id": "F9pTP3LY2a3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility function, rgb to hex\n",
        "def rgb2hex(rgb):\n",
        "    hex = \"#{:02x}{:02x}{:02x}\".format(int(rgb[0]), int(rgb[1]), int(rgb[2]))\n",
        "    return hex\n",
        "print(rgb2hex([255, 0, 0]))"
      ],
      "metadata": {
        "id": "IwiPXVDq3ujC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_color_cluster(path, k=6):\n",
        "    # load image\n",
        "    img_bgr = cv2.imread(path)\n",
        "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # resize image to speed up processing time\n",
        "    resized_img_rgb = cv2.resize(img_rgb, (64, 64), interpolation=cv2.INTER_AREA)\n",
        "    resized_img_rgb = img_rgb\n",
        "\n",
        "    # reshape the image to be a list of pixels\n",
        "    img_list = resized_img_rgb.reshape((resized_img_rgb.shape[0] * resized_img_rgb.shape[1], 3))\n",
        "\n",
        "    # cluster the pixels and assign labels\n",
        "    clt = KMeans(n_clusters=k)\n",
        "    labels = clt.fit_predict(img_list)\n",
        "\n",
        "    # count labels to find most popular\n",
        "    label_counts = Counter(labels)\n",
        "    total_count = sum(label_counts.values())\n",
        "\n",
        "    # subset out most popular centroid\n",
        "    center_colors = list(clt.cluster_centers_)\n",
        "    ordered_colors = [center_colors[i]/255 for i in label_counts.keys()]\n",
        "    color_labels = [rgb2hex(ordered_colors[i]*255) for i in label_counts.keys()]\n",
        "\n",
        "    #print(label_counts.values())\n",
        "    #print(color_labels)\n",
        "\n",
        "    # plots\n",
        "    plt.figure(figsize=(14, 8))\n",
        "    #plt.subplot(221)\n",
        "    #plt.imshow(img_rgb)\n",
        "    #plt.axis('off')\n",
        "\n",
        "    #plt.subplot(222)\n",
        "    plt.pie(label_counts.values(), labels=color_labels, colors=ordered_colors, startangle=90)\n",
        "    plt.axis('equal')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "cGXT4vx137MC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = 'images/ibs-92.jpg'  # Replace with your image path\n",
        "image_color_cluster(image_path, k=5)"
      ],
      "metadata": {
        "id": "bhW6jpLM4Nn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# video dataset"
      ],
      "metadata": {
        "id": "UwbWedZR1lE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1T9S32UwmDnUd6YbxRYfyG7-gud8jh2Y_\n"
      ],
      "metadata": {
        "id": "FFnmjMCX-2wL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "# Path to the video file\n",
        "video_path = 'content-video.mp4'\n",
        "\n",
        "# Create a VideoCapture object\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Check if video opened successfully\n",
        "if not cap.isOpened():\n",
        "    print(\"Error: Could not open video.\")\n",
        "    exit()\n",
        "\n",
        "# Directory to save frames\n",
        "save_dir = 'images-video'\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "frame_idx = 0\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    # Break the loop if there are no more frames\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Save every 100th frame\n",
        "    if frame_idx % 100 == 0:\n",
        "        # Filename with 5 leading zeroes\n",
        "        save_path = os.path.join(save_dir, f'frame_{frame_idx:05d}.jpg')\n",
        "        cv2.imwrite(save_path, frame)\n",
        "        print(f'Saved frame {frame_idx:05d}')\n",
        "\n",
        "    frame_idx += 1\n",
        "\n",
        "# Release the VideoCapture object\n",
        "cap.release()\n"
      ],
      "metadata": {
        "id": "x5k3-XKp-6fu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# image ocr"
      ],
      "metadata": {
        "id": "OKRDj4zw5fW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q easyocr\n"
      ],
      "metadata": {
        "id": "k1QYaSVP8o4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import easyocr"
      ],
      "metadata": {
        "id": "135SsUj35eL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reader = easyocr.Reader(['ch_tra', 'en', 'sv'])\n",
        "reader = easyocr.Reader(['en'])"
      ],
      "metadata": {
        "id": "nJm1sLwn5o01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = reader.readtext('images-video/frame_00400.jpg')\n",
        "result"
      ],
      "metadata": {
        "id": "tQCi0rKz5scR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reader.readtext('images-video/frame_00400.jpg', detail=0)"
      ],
      "metadata": {
        "id": "6HIh-Oyk5vhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# image normalization"
      ],
      "metadata": {
        "id": "R85rRHYK5iI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "def resize_and_crop(img, size):\n",
        "    # Resize image to maintain aspect ratio\n",
        "    h, w, _ = img.shape\n",
        "    if h > w:\n",
        "        new_h, new_w = size * h / w, size\n",
        "    else:\n",
        "        new_h, new_w = size, size * w / h\n",
        "\n",
        "    new_h, new_w = int(new_h), int(new_w)\n",
        "    resized_img = cv2.resize(img, (new_w, new_h))\n",
        "\n",
        "    # Crop the center of the image\n",
        "    startx = new_w//2 - size//2\n",
        "    starty = new_h//2 - size//2\n",
        "    return resized_img[starty:starty+size, startx:startx+size]\n",
        "\n",
        "def normalize_image(img):\n",
        "    # Normalize pixel values to [0, 1]\n",
        "    return img / 255.0\n",
        "\n",
        "directory = 'images'\n",
        "output_directory = 'images-normalize'\n",
        "\n",
        "if not os.path.exists(output_directory):\n",
        "    os.makedirs(output_directory)\n",
        "\n",
        "for filename in os.listdir(directory):\n",
        "    if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
        "#    if filename.endswith('.jpg'):\n",
        "        img = cv2.imread(os.path.join(directory, filename))\n",
        "        img = resize_and_crop(img, 256)\n",
        "        normalized_img = normalize_image(img)\n",
        "\n",
        "        # Convert the normalized image back to 8-bit format\n",
        "        img_to_save = (normalized_img * 255).astype(np.uint8)\n",
        "\n",
        "        # Save the normalized image\n",
        "        output_path = os.path.join(output_directory, filename)\n",
        "        cv2.imwrite(output_path, img_to_save)\n"
      ],
      "metadata": {
        "id": "hjI2Iu-Z-_py"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def extract_orb_features(image):\n",
        "    \"\"\"Extract ORB features from an image.\"\"\"\n",
        "    orb = cv2.ORB_create()\n",
        "    keypoints, descriptors = orb.detectAndCompute(image, None)\n",
        "    if descriptors is None:\n",
        "        return np.zeros((1, orb.descriptorSize()), dtype=np.float32)\n",
        "    return descriptors\n",
        "\n",
        "def calculate_similarity(descriptor_list):\n",
        "    \"\"\"Calculate similarity scores using feature matching.\"\"\"\n",
        "    num_images = len(descriptor_list)\n",
        "    similarity_matrix = np.zeros((num_images, num_images))\n",
        "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
        "\n",
        "    for i in range(num_images):\n",
        "        for j in range(i, num_images):\n",
        "            if i == j:\n",
        "                similarity_matrix[i, j] = 1\n",
        "            else:\n",
        "                # Ensure the descriptors are in the correct type\n",
        "                desc1 = descriptor_list[i].astype(np.uint8)\n",
        "                desc2 = descriptor_list[j].astype(np.uint8)\n",
        "\n",
        "                matches = bf.match(desc1, desc2)\n",
        "                score = len(matches) / max(len(desc1), len(desc2))\n",
        "                similarity_matrix[i, j] = score\n",
        "                similarity_matrix[j, i] = score\n",
        "\n",
        "    return similarity_matrix\n",
        "\n",
        "# Directory containing images\n",
        "image_directory = 'images-normalize'  # Replace with your directory path\n",
        "\n",
        "# Load and process images\n",
        "image_files = [f for f in os.listdir(image_directory) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "orb_descriptors = []\n",
        "\n",
        "for file in image_files:\n",
        "    image_path = os.path.join(image_directory, file)\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    descriptors = extract_orb_features(image)\n",
        "    orb_descriptors.append(descriptors)\n",
        "\n",
        "# Calculate the similarity matrix\n",
        "similarity_matrix = calculate_similarity(orb_descriptors)\n",
        "\n",
        "# Plotting the similarity matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(similarity_matrix, annot=True, cmap='coolwarm')\n",
        "plt.title('ORB Feature Similarity Matrix')\n",
        "plt.xlabel('Image Index')\n",
        "plt.ylabel('Image Index')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "VBALk5Rq8z1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def compute_histogram(image, bins=256):\n",
        "    \"\"\"Compute the color histogram for an image.\"\"\"\n",
        "    histogram = [cv2.calcHist([image], [i], None, [bins], [0, 256]) for i in range(3)]\n",
        "    return np.concatenate(histogram).flatten()\n",
        "\n",
        "def calculate_similarity(hist_list):\n",
        "    \"\"\"Calculate histogram similarity matrix.\"\"\"\n",
        "    num_images = len(hist_list)\n",
        "    similarity_matrix = np.zeros((num_images, num_images))\n",
        "\n",
        "    for i in range(num_images):\n",
        "        for j in range(num_images):\n",
        "            similarity = cv2.compareHist(hist_list[i], hist_list[j], cv2.HISTCMP_CORREL)\n",
        "            similarity_matrix[i, j] = similarity\n",
        "\n",
        "    return similarity_matrix\n",
        "\n",
        "# Directory containing images\n",
        "image_directory = 'images'  # Replace with your directory path\n",
        "image_directory = 'images-normalize'  # Replace with your directory path\n",
        "\n",
        "# Load and process images\n",
        "image_files = [f for f in os.listdir(image_directory) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "histograms = []\n",
        "\n",
        "for file in image_files:\n",
        "    image_path = os.path.join(image_directory, file)\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is not None:\n",
        "        hist = compute_histogram(image)\n",
        "        histograms.append(hist)\n",
        "\n",
        "# Calculate the similarity matrix\n",
        "similarity_matrix = calculate_similarity(histograms)\n",
        "\n",
        "# Plotting the similarity matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(similarity_matrix, annot=True, cmap='coolwarm')\n",
        "plt.title('Image Histogram Similarity Matrix')\n",
        "plt.xlabel('Image Index')\n",
        "plt.ylabel('Image Index')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "iaDJGyNa9ANi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "\n",
        "# Function to compute the color histogram and similarity matrix\n",
        "# ... (same functions `compute_histogram` and `calculate_similarity` as before)\n",
        "\n",
        "# Directory containing images\n",
        "image_directory = 'images'  # Replace with your directory path\n",
        "image_directory = 'images-normalize'  # Replace with your directory path\n",
        "\n",
        "# Load and process images\n",
        "image_files = [f for f in os.listdir(image_directory) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "histograms = []\n",
        "\n",
        "for file in image_files:\n",
        "    image_path = os.path.join(image_directory, file)\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is not None:\n",
        "        hist = compute_histogram(image)\n",
        "        histograms.append(hist)\n",
        "\n",
        "# Calculate the similarity matrix\n",
        "similarity_matrix = calculate_similarity(histograms)\n",
        "\n",
        "# Perform hierarchical clustering\n",
        "Z = linkage(1 - similarity_matrix, method='average')\n",
        "\n",
        "# Plot dendrogram\n",
        "plt.figure(figsize=(12, 8))\n",
        "dendrogram(Z, labels=image_files, orientation='right')\n",
        "plt.title('Hierarchical Clustering Dendrogram')\n",
        "plt.xlabel('Distance')\n",
        "plt.ylabel('Image')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9MWlmZxJFsX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# image object detection"
      ],
      "metadata": {
        "id": "HPGeKJyR7MRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers\n",
        "!pip install -q timm\n"
      ],
      "metadata": {
        "id": "VN6t5-Nl7SY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "model = pipeline(\"object-detection\")"
      ],
      "metadata": {
        "id": "HT-Lm8eI7Qwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "rows_list = []\n",
        "for img in sorted(glob.glob('images-video/frame_*.jpg')):\n",
        "  dict1 = {}\n",
        "  res = model(img)\n",
        "  dict1.update({\"image\": img, \"result\": res})\n",
        "  rows_list.append(dict1)\n",
        "\n",
        "df = pd.DataFrame(rows_list)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "IYTtPDg17kJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rows_list = []\n",
        "for index, row in df.iterrows():\n",
        "  for i in row.result:\n",
        "    dict1 = {}\n",
        "    dict1.update({\"image\":row.image})\n",
        "    dict1.update(i)\n",
        "    rows_list.append(dict1)\n",
        "\n",
        "df_res = pd.DataFrame(rows_list)\n",
        "df_res.head()"
      ],
      "metadata": {
        "id": "mJbf6_6Y9cCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_res.label.value_counts().plot(kind='bar')"
      ],
      "metadata": {
        "id": "MiaHR_1P9kjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_res[df_res.image==\"images-video/frame_00100.jpg\"]"
      ],
      "metadata": {
        "id": "SbVliiwf9osW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "img = cv2.imread('images-video/frame_00100.jpg')\n",
        "for index,row in df_res[df_res.image==\"images-video/frame_00100.jpg\"].iterrows():\n",
        "  x1,y1,x2,y2 = list(row.box.values())\n",
        "  cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow(img)\n",
        "#cv2.imshow(\"display\", img)\n",
        "#cv2.imwrite(\"objects.png\", img)"
      ],
      "metadata": {
        "id": "xqUe8ol493s9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# image content inference"
      ],
      "metadata": {
        "id": "YO6lKKWSPsc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q mediapipe"
      ],
      "metadata": {
        "id": "1MUyIjCoG6hm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initialize MediaPipe Pose\n",
        "mp_pose = mp.solutions.pose\n",
        "pose = mp_pose.Pose(static_image_mode=True, model_complexity=1, enable_segmentation=True)\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "\n",
        "# Read an image\n",
        "image_path = 'images-video/frame_02800.jpg'  # Replace with the path to your image\n",
        "image_path = 'images-video/frame_00400.jpg'  # Replace with the path to your image\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# Check if image is loaded\n",
        "if image is None:\n",
        "    print(\"Error: Image not found.\")\n",
        "else:\n",
        "    # Convert the BGR image to RGB\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Process the image and find the pose\n",
        "    results = pose.process(image_rgb)\n",
        "\n",
        "    # Draw pose landmarks on the image\n",
        "    if results.pose_landmarks:\n",
        "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
        "\n",
        "    # Convert back to BGR for displaying with OpenCV\n",
        "    image_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    # Display the image\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Release resources\n",
        "pose.close()\n"
      ],
      "metadata": {
        "id": "l93XkAq4PzNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YZt6W4H6QvI8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}