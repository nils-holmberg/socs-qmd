{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Day 5: Finishing with data collections\"\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "{{< include _include_d5.qmd >}}\n",
        "\n",
        "## Web scraping\n",
        "\n",
        "The content of the webpage \"https://books.toscrape.com/catalogue/page-2.html\" was fetched using the `requests` library. Once retrieved, the content was saved as an HTML file named \"books_page_2.html\". The `Beautiful Soup` library was then employed to parse and analyze the HTML structure. The analysis focused on identifying all `article` tags with the class `product_pod`. Within each of these tags, the title and link attributes from the nested `h3` and `a` tags were extracted. This extracted data was subsequently organized into a pandas dataframe, displaying the title of each book alongside its corresponding link."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: true\n",
        "#| echo: true\n",
        "#| output: true\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# URL to fetch\n",
        "books_url = 'https://books.toscrape.com/catalogue/page-2.html'\n",
        "\n",
        "# Make a request to the website using the requests library\n",
        "books_response = requests.get(books_url)\n",
        "books_content = books_response.content\n",
        "\n",
        "# Save the content to an HTML file\n",
        "books_filename = '../../xml/books_page_2.html'\n",
        "with open(books_filename, 'wb') as file:\n",
        "    file.write(books_content)\n",
        "\n",
        "# Parse the content with BeautifulSoup\n",
        "books_soup = BeautifulSoup(books_content, 'lxml')\n",
        "\n",
        "# Look for all article tags of class 'product_pod'\n",
        "product_pods = books_soup.find_all('article', class_='product_pod')\n",
        "\n",
        "# Extract the h3 child tag and its a tag attributes as text\n",
        "books_data = []\n",
        "for pod in product_pods:\n",
        "    h3_tag = pod.find('h3')\n",
        "    a_tag = h3_tag.find('a') if h3_tag else None\n",
        "    books_data.append({\n",
        "        'title': a_tag.attrs.get('title') if a_tag else None,\n",
        "        'link': a_tag.attrs.get('href') if a_tag else None\n",
        "    })\n",
        "\n",
        "# Convert the data to a pandas dataframe\n",
        "books_df = pd.DataFrame(books_data)\n",
        "books_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Survey experiments\n",
        "\n",
        "- Upcoming, streamlit ? pyscript ? shiny ?\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}